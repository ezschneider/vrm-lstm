{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw: pd.DataFrame = pd.read_csv(\n",
    "    '../data/processed_data.csv',\n",
    "    parse_dates=[\"Time\"],\n",
    "    index_col=[0],\n",
    "    sep=';'\n",
    ")\n",
    "\n",
    "threshold = 1500\n",
    "df = df_raw[df_raw['Corrente motor'] > threshold]\n",
    "\n",
    "# Drop all rows with NaN values\n",
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vibration_windows(df, feature_column='feature', window_size=30, threshold=1.5):\n",
    "    # Step 1: Identify indices where the feature column value is greater than the threshold\n",
    "    end_indices = np.where(df[feature_column] > threshold)[0]\n",
    "\n",
    "    # Step 2: Create windows of the specified size ending at these indices\n",
    "    windows = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for idx in end_indices:\n",
    "        start_idx = idx - (window_size - 1)  # Calculate the start of the window\n",
    "        if start_idx < 0:\n",
    "            continue  # Skip windows that start before the beginning of the DataFrame\n",
    "\n",
    "        # Check if the window overlaps with any already used indices\n",
    "        if any(i in used_indices for i in range(start_idx, idx + 1)):\n",
    "            continue  # Skip overlapping windows\n",
    "\n",
    "        # Add the window to the list of windows\n",
    "        windows.append(df.iloc[start_idx:idx + 1])\n",
    "\n",
    "        # Mark the indices as used\n",
    "        used_indices.update(range(start_idx, idx + 1))\n",
    "\n",
    "    return windows\n",
    "\n",
    "def create_non_vibration_windows(df, critical_windows, feature_column='feature', threshold=1.5):\n",
    "    # Criar janelas não críticas (exemplo: janelas aleatórias abaixo do threshold)\n",
    "    non_critical_windows = []\n",
    "    for _ in range(len(critical_windows)):  # Criar o mesmo número de janelas não críticas\n",
    "        start_idx = np.random.randint(0, len(df) - 30)  # Escolher um índice aleatório\n",
    "        window = df.iloc[start_idx:start_idx + 30]\n",
    "        if window[feature_column].max() <= threshold:  # Garantir que a janela não é crítica\n",
    "            non_critical_windows.append(window)\n",
    "\n",
    "    return non_critical_windows\n",
    "\n",
    "def remove_problematic_columns(df):\n",
    "    # Lista para armazenar colunas a serem removidas\n",
    "    columns_to_drop = []\n",
    "\n",
    "    # Verifica cada coluna no DataFrame\n",
    "    for col in df.columns:\n",
    "        # Verifica se a coluna contém tipos de dados não numéricos\n",
    "        if df[col].dtype == 'object':\n",
    "            print(f\"Coluna '{col}' removida: contém tipo de dados 'object'.\")\n",
    "            columns_to_drop.append(col)\n",
    "            continue\n",
    "\n",
    "        # Verifica se a coluna contém valores não numéricos (NaN, infinito, etc.)\n",
    "        if not np.isfinite(df[col]).all():\n",
    "            print(f\"Coluna '{col}' removida: contém valores não numéricos (NaN ou infinito).\")\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    # Remove as colunas problemáticas\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna 'Unnamed: 58' removida: contém tipo de dados 'object'.\n"
     ]
    }
   ],
   "source": [
    "df = remove_problematic_columns(df)\n",
    "\n",
    "critical_windows = create_vibration_windows(df)\n",
    "non_critical_windows = create_non_vibration_windows(df, critical_windows)\n",
    "\n",
    "# Rotular as janelas\n",
    "critical_labels = [1] * len(critical_windows)  # 1 para críticas\n",
    "non_critical_labels = [0] * len(non_critical_windows)  # 0 para não críticas\n",
    "\n",
    "# Combinar janelas e rótulos\n",
    "windows = critical_windows + non_critical_windows\n",
    "labels = critical_labels + non_critical_labels\n",
    "\n",
    "# Converter janelas para numpy array (formato adequado para modelos)\n",
    "X = np.array([window.values for window in windows])  # Usar todas as colunas da janela\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5285 - loss: 953.3416 - val_accuracy: 0.6024 - val_loss: 70.4006\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 136.8660 - val_accuracy: 0.5904 - val_loss: 30.8465\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5537 - loss: 44.1773 - val_accuracy: 0.5904 - val_loss: 7.0596\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 8.1590 - val_accuracy: 0.5976 - val_loss: 2.0961\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 2.0425 - val_accuracy: 0.5928 - val_loss: 2.0915\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6425 - loss: 1.4028 - val_accuracy: 0.5880 - val_loss: 1.5457\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 1.0268 - val_accuracy: 0.6024 - val_loss: 1.1661\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6255 - loss: 1.0659 - val_accuracy: 0.5928 - val_loss: 0.7517\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6311 - loss: 0.8665 - val_accuracy: 0.6024 - val_loss: 0.8306\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 0.7506 - val_accuracy: 0.5663 - val_loss: 0.8490\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 0.7858 - val_accuracy: 0.5663 - val_loss: 0.7675\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5673 - loss: 0.7176 - val_accuracy: 0.5663 - val_loss: 0.7259\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.6819 - val_accuracy: 0.5952 - val_loss: 0.7210\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6256 - loss: 0.6766 - val_accuracy: 0.5639 - val_loss: 0.7872\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.7375 - val_accuracy: 0.5639 - val_loss: 0.8759\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.7774 - val_accuracy: 0.5952 - val_loss: 1.0814\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 0.7002 - val_accuracy: 0.5663 - val_loss: 0.7257\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.6844 - val_accuracy: 0.5614 - val_loss: 0.7099\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5717 - loss: 0.7635 - val_accuracy: 0.5663 - val_loss: 0.7398\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5682 - loss: 0.7701 - val_accuracy: 0.5687 - val_loss: 0.7508\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.7098 - val_accuracy: 0.5639 - val_loss: 0.7449\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 1.1217 - val_accuracy: 0.5687 - val_loss: 0.7226\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5778 - loss: 0.7207 - val_accuracy: 0.5663 - val_loss: 0.6897\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.6820 - val_accuracy: 0.5663 - val_loss: 0.6909\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.7317 - val_accuracy: 0.5663 - val_loss: 0.6955\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.6726 - val_accuracy: 0.5639 - val_loss: 0.6986\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.6814 - val_accuracy: 0.5639 - val_loss: 0.6974\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.6833 - val_accuracy: 0.5687 - val_loss: 0.6928\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.6741 - val_accuracy: 0.5663 - val_loss: 0.6942\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.6759 - val_accuracy: 0.5639 - val_loss: 0.6960\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.6753 - val_accuracy: 0.5663 - val_loss: 0.6850\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5696 - loss: 0.6815 - val_accuracy: 0.5639 - val_loss: 0.7004\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.6978 - val_accuracy: 0.5663 - val_loss: 0.6821\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5690 - loss: 0.6829 - val_accuracy: 0.5663 - val_loss: 0.6853\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 0.6753 - val_accuracy: 0.5663 - val_loss: 0.6867\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.6841 - val_accuracy: 0.5663 - val_loss: 0.7071\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 0.6798 - val_accuracy: 0.5663 - val_loss: 0.6906\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.6732 - val_accuracy: 0.5663 - val_loss: 0.6887\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.6697 - val_accuracy: 0.5663 - val_loss: 0.6893\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 0.6771 - val_accuracy: 0.5663 - val_loss: 0.6897\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 0.6648 - val_accuracy: 0.5663 - val_loss: 0.6909\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5735 - loss: 0.6787 - val_accuracy: 0.5663 - val_loss: 0.6902\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.6756 - val_accuracy: 0.5663 - val_loss: 0.6820\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.6737 - val_accuracy: 0.5663 - val_loss: 0.6845\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.6716 - val_accuracy: 0.5663 - val_loss: 0.6858\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 0.6969 - val_accuracy: 0.5663 - val_loss: 0.6820\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.6765 - val_accuracy: 0.5663 - val_loss: 0.6868\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.6702 - val_accuracy: 0.5663 - val_loss: 0.6883\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.6833 - val_accuracy: 0.5639 - val_loss: 0.6868\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.8559 - val_accuracy: 0.5590 - val_loss: 0.8664\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5520 - loss: 1.1239\n",
      "Acurácia: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Redimensionar X para o formato esperado pelo MLP (amostras, timesteps * n_features)\n",
    "X_train_mlp = X_train.reshape(X_train.shape[0], -1)  # Achatar as dimensões de timesteps e features\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Construir o modelo\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train_mlp.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Saída binária (crítica ou não crítica)\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train_mlp, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test_mlp, y_test)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.6657 - val_accuracy: 0.5952 - val_loss: 0.6714\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6115 - loss: 0.6677 - val_accuracy: 0.5952 - val_loss: 0.6801\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6233 - loss: 0.6633 - val_accuracy: 0.5952 - val_loss: 0.6778\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6412 - loss: 0.6554 - val_accuracy: 0.5952 - val_loss: 0.6699\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 0.6682 - val_accuracy: 0.6024 - val_loss: 0.6732\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6203 - loss: 0.6647 - val_accuracy: 0.6024 - val_loss: 0.6764\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6325 - loss: 0.6650 - val_accuracy: 0.6024 - val_loss: 0.6704\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6154 - loss: 0.6646 - val_accuracy: 0.6024 - val_loss: 0.6731\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6243 - loss: 0.6614 - val_accuracy: 0.6024 - val_loss: 0.6704\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6269 - loss: 0.6552 - val_accuracy: 0.6024 - val_loss: 0.6732\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6421 - loss: 0.6493 - val_accuracy: 0.6024 - val_loss: 0.6695\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6396 - loss: 0.6556 - val_accuracy: 0.6024 - val_loss: 0.6693\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6522 - loss: 0.6464 - val_accuracy: 0.6000 - val_loss: 0.6691\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6467 - loss: 0.6494 - val_accuracy: 0.6000 - val_loss: 0.6698\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6237 - loss: 0.6585 - val_accuracy: 0.6000 - val_loss: 0.6735\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6311 - loss: 0.6551 - val_accuracy: 0.6000 - val_loss: 0.6698\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6289 - loss: 0.6642 - val_accuracy: 0.6000 - val_loss: 0.6701\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6166 - loss: 0.6615 - val_accuracy: 0.6000 - val_loss: 0.6732\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6449 - loss: 0.6472 - val_accuracy: 0.6000 - val_loss: 0.6708\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6300 - loss: 0.6503 - val_accuracy: 0.6000 - val_loss: 0.6705\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - loss: 0.6484 - val_accuracy: 0.6000 - val_loss: 0.6704\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.6563 - val_accuracy: 0.6000 - val_loss: 0.6725\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6388 - loss: 0.6576 - val_accuracy: 0.6000 - val_loss: 0.6698\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6322 - loss: 0.6602 - val_accuracy: 0.6000 - val_loss: 0.6702\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6297 - loss: 0.6533 - val_accuracy: 0.6000 - val_loss: 0.6714\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6289 - loss: 0.6541 - val_accuracy: 0.6000 - val_loss: 0.6698\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6410 - loss: 0.6544 - val_accuracy: 0.6000 - val_loss: 0.6700\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6420 - loss: 0.6520 - val_accuracy: 0.6000 - val_loss: 0.6698\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6174 - loss: 0.6647 - val_accuracy: 0.6000 - val_loss: 0.6702\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6321 - loss: 0.6482 - val_accuracy: 0.6000 - val_loss: 0.6722\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6356 - loss: 0.6558 - val_accuracy: 0.6000 - val_loss: 0.6705\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6235 - loss: 0.6602 - val_accuracy: 0.6000 - val_loss: 0.6713\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6275 - loss: 0.6593 - val_accuracy: 0.6000 - val_loss: 0.6709\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6414 - loss: 0.6533 - val_accuracy: 0.6000 - val_loss: 0.6706\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6536 - loss: 0.6444 - val_accuracy: 0.6000 - val_loss: 0.6702\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6348 - loss: 0.6531 - val_accuracy: 0.6000 - val_loss: 0.6745\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.6580 - val_accuracy: 0.6000 - val_loss: 0.6725\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6269 - loss: 0.6518 - val_accuracy: 0.6000 - val_loss: 0.6724\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6396 - loss: 0.6498 - val_accuracy: 0.6000 - val_loss: 0.6702\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6318 - loss: 0.6501 - val_accuracy: 0.6000 - val_loss: 0.6734\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6363 - loss: 0.6508 - val_accuracy: 0.6000 - val_loss: 0.6718\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6233 - loss: 0.6581 - val_accuracy: 0.6000 - val_loss: 0.6727\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 0.6635 - val_accuracy: 0.6000 - val_loss: 0.6708\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6422 - loss: 0.6523 - val_accuracy: 0.6000 - val_loss: 0.6705\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6327 - loss: 0.6535 - val_accuracy: 0.6000 - val_loss: 0.6714\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6409 - loss: 0.6503 - val_accuracy: 0.6000 - val_loss: 0.6701\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6486 - loss: 0.6506 - val_accuracy: 0.6000 - val_loss: 0.6701\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6144 - loss: 0.6644 - val_accuracy: 0.6000 - val_loss: 0.6746\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6379 - loss: 0.6529 - val_accuracy: 0.6000 - val_loss: 0.6699\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6362 - loss: 0.6511 - val_accuracy: 0.6000 - val_loss: 0.6705\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.6654 \n",
      "Acurácia: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Construir o modelo\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(64),  # (timesteps, n_features)\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Saída binária (crítica ou não crítica)\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5428 - loss: 900.4799 - val_accuracy: 0.5952 - val_loss: 34.4132\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 128.1469 - val_accuracy: 0.5783 - val_loss: 11.1925\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 72.9502 - val_accuracy: 0.6072 - val_loss: 15.9382\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5922 - loss: 34.7849 - val_accuracy: 0.5855 - val_loss: 10.9763\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5664 - loss: 18.2298 - val_accuracy: 0.6265 - val_loss: 6.8454\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5776 - loss: 10.2846 - val_accuracy: 0.4651 - val_loss: 4.0118\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5673 - loss: 4.9113 - val_accuracy: 0.5542 - val_loss: 3.6096\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5665 - loss: 3.8580 - val_accuracy: 0.5831 - val_loss: 2.7898\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 1.8744 - val_accuracy: 0.5976 - val_loss: 2.3943\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6127 - loss: 2.2162 - val_accuracy: 0.6000 - val_loss: 2.7092\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6198 - loss: 1.9588 - val_accuracy: 0.5687 - val_loss: 1.8510\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: 1.4259 - val_accuracy: 0.5566 - val_loss: 1.7447\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 1.6342 - val_accuracy: 0.5687 - val_loss: 1.8485\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.9923 - val_accuracy: 0.5663 - val_loss: 2.2866\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.9795 - val_accuracy: 0.5590 - val_loss: 2.0487\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6037 - loss: 0.9868 - val_accuracy: 0.5663 - val_loss: 1.9091\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 1.1747 - val_accuracy: 0.5759 - val_loss: 1.8366\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 0.7935 - val_accuracy: 0.5566 - val_loss: 1.8560\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5901 - loss: 1.2813 - val_accuracy: 0.5687 - val_loss: 1.8599\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.8083 - val_accuracy: 0.5566 - val_loss: 1.8696\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.9268 - val_accuracy: 0.5614 - val_loss: 1.7680\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6392 - loss: 0.7087 - val_accuracy: 0.5663 - val_loss: 1.7543\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.9378 - val_accuracy: 0.5542 - val_loss: 2.2134\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 1.1357 - val_accuracy: 0.5759 - val_loss: 1.8806\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 0.9202 - val_accuracy: 0.5687 - val_loss: 1.6469\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.7318 - val_accuracy: 0.5663 - val_loss: 1.6489\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6286 - loss: 0.9306 - val_accuracy: 0.5663 - val_loss: 1.7490\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.9749 - val_accuracy: 0.6000 - val_loss: 1.6908\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6394 - loss: 0.9677 - val_accuracy: 0.6000 - val_loss: 1.4850\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6527 - loss: 1.0227 - val_accuracy: 0.5952 - val_loss: 1.7595\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6431 - loss: 0.8727 - val_accuracy: 0.6024 - val_loss: 1.5436\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 0.6690 - val_accuracy: 0.5928 - val_loss: 1.7928\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 0.7022 - val_accuracy: 0.5952 - val_loss: 1.7916\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6285 - loss: 1.3188 - val_accuracy: 0.6169 - val_loss: 1.2849\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6180 - loss: 0.8747 - val_accuracy: 0.5928 - val_loss: 1.8442\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6432 - loss: 0.7312 - val_accuracy: 0.5976 - val_loss: 1.6088\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 0.7464 - val_accuracy: 0.5976 - val_loss: 1.3911\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6517 - loss: 0.6571 - val_accuracy: 0.5952 - val_loss: 1.7001\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.7287 - val_accuracy: 0.5952 - val_loss: 2.0049\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.8432 - val_accuracy: 0.6000 - val_loss: 1.9489\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6475 - loss: 0.7805 - val_accuracy: 0.6048 - val_loss: 1.8854\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6476 - loss: 1.0591 - val_accuracy: 0.5976 - val_loss: 1.3954\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6401 - loss: 0.6904 - val_accuracy: 0.6024 - val_loss: 1.4347\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6373 - loss: 0.8458 - val_accuracy: 0.6048 - val_loss: 1.3472\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 0.8275 - val_accuracy: 0.6048 - val_loss: 1.3001\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6343 - loss: 0.7090 - val_accuracy: 0.6000 - val_loss: 1.3470\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6274 - loss: 0.7732 - val_accuracy: 0.6024 - val_loss: 1.3329\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6427 - loss: 0.6732 - val_accuracy: 0.6024 - val_loss: 1.2712\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6442 - loss: 0.8456 - val_accuracy: 0.6024 - val_loss: 1.1472\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 0.7382 - val_accuracy: 0.6000 - val_loss: 1.1818\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5934 - loss: 9.0997 \n",
      "Acurácia: 0.60\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "# Construir o modelo\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Saída binária (crítica ou não crítica)\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
